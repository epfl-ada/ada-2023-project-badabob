{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import spacy\n",
    "#spacy.cli.download(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wikipedia_ID</th>\n",
       "      <th>plot_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23890098</td>\n",
       "      <td>Shlykov, a hard-working taxi driver and Lyosha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31186339</td>\n",
       "      <td>The nation of Panem consists of a wealthy Capi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20663735</td>\n",
       "      <td>Poovalli Induchoodan  is sentenced for six yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2231378</td>\n",
       "      <td>The Lemon Drop Kid , a New York City swindler,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>595909</td>\n",
       "      <td>Seventh-day Adventist Church pastor Michael Ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wikipedia_ID                                       plot_summary\n",
       "0      23890098  Shlykov, a hard-working taxi driver and Lyosha...\n",
       "1      31186339  The nation of Panem consists of a wealthy Capi...\n",
       "2      20663735  Poovalli Induchoodan  is sentenced for six yea...\n",
       "3       2231378  The Lemon Drop Kid , a New York City swindler,...\n",
       "4        595909  Seventh-day Adventist Church pastor Michael Ch..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = './Data/'\n",
    "plot_summaries = pd.read_csv(data_folder+'plot_summaries.txt',sep='\\t', header=None, names=['wikipedia_ID', 'plot_summary'] )\n",
    "df = plot_summaries[:10]\n",
    "\n",
    "\"\"\"\n",
    "for ind in range(10):\n",
    "    print()\n",
    "    print(plot_summaries.iloc[ind]['plot_summary'])\n",
    "\"\"\"\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import re\n",
    "import string\n",
    "from itertools import combinations\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorising done\n",
      "nlp model loading done\n",
      "[('Indulekha', 5), ('Menon', 4), ('Manapally Madhavan Nambiar', 2), ('Manapally', 2), ('Anuradha', 2), ('Poovalli Induchoodan', 1), ('Karunakara Menon', 1), ('DYSP Sankaranarayanan', 1), ('Manapally Sudheeran', 1), ('Moopil Nair', 1), ('Nambiar', 1), ('Mooppil Nair', 1), ('Kanaka', 1), ('Manapally Pavithran', 1), ('Jayakrishnan', 1), ('Raman Nair', 1), ('Nandagopal Maarar', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Text preprocessing and TF-IDF vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['plot_summary'])\n",
    "print(\"vectorising done\") # 10 seconds\n",
    "\n",
    "# Named Entity Recognition using SpaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "print(\"nlp model loading done\")\n",
    "\n",
    "def extract_characters(text):\n",
    "    doc = nlp(text)\n",
    "    names = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "    characters = []\n",
    "    for name in names:\n",
    "        characters.append(name.translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "    ordered_characters = Counter(characters).most_common()\n",
    "\n",
    "    return ordered_characters\n",
    "\n",
    "\"\"\"\n",
    "df['characters'] = df['plot_summary'].apply(extract_characters)\n",
    "\n",
    "for ind in range(10):\n",
    "    print()\n",
    "    print(df.iloc[ind]['characters'])\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(extract_characters(df.iloc[2]['plot_summary']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Aveek's Blog\n",
    "https://home.aveek.io/blog/post/finding-main-characters/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/julian/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/julian/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    " \n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import string\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    " \n",
    " \n",
    "from flair.models import SequenceTagger\n",
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-12 12:56:16,800 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:28<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Induchoodan', 17), ('Menon', 9), ('Indulekha', 6), ('Manapally Pavithran', 3), ('Pavithran', 3), ('Manapally Madhavan Nambiar', 2), ('Manapally', 2), ('Anuradha', 2), ('Justice Menon', 2), ('Poovalli Induchoodan', 1), ('Justice Maranchery Karunakara Menon', 1), ('DYSP Sankaranarayanan', 1), ('Manapally Sudheeran', 1), ('Saikumar', 1), ('Ramakrishnan', 1), ('Moopil Nair', 1), ('Nambiar', 1), ('Aishwarya', 1), ('Mooppil Nair', 1), ('Kanaka', 1), ('Chandrabhanu', 1), ('Jayakrishnan', 1), ('Raman Nair', 1), ('Nandagopal Maarar', 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tagger = SequenceTagger.load('ner')\n",
    "\n",
    "def extract_characters(summary:str):\n",
    "    sentences = sent_tokenize(summary)\n",
    "    x = []\n",
    "    for line in tqdm(sentences):\n",
    "        sentence = Sentence(line)\n",
    "        tagger.predict(sentence)\n",
    "        for entity in sentence.to_dict(tag_type='ner')['entities']:\n",
    "            if entity['labels'][0]['value'] == 'PER':\n",
    "                x.append(entity['text'])\n",
    "    names = []\n",
    "    for name in x:\n",
    "        names.append(name.translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "    ordered_names = Counter(names).most_common()\n",
    " \n",
    "    return ordered_names\n",
    "\n",
    "\n",
    "print(extract_characters(df.iloc[2]['plot_summary']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chatgpt optimized version of Aveek's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-12 13:04:44,471 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
      "\n",
      "[('Shlykov', 1), ('Lyosha', 1)]\n",
      "\n",
      "[('Katniss', 24), ('Peeta', 14), ('Rue', 9), ('Cato', 4), ('Haymitch', 3), ('Crane', 3), ('Clove', 3), ('Snow', 2), ('Thresh', 2), ('Peeta Mellark', 1), ('Haymitch Abernathy', 1), ('Caesar Flickerman', 1), ('Glimmer', 1), ('Seneca Crane', 1), ('Foxface', 1)]\n",
      "\n",
      "[('Induchoodan', 17), ('Menon', 9), ('Indulekha', 6), ('Manapally Pavithran', 3), ('Pavithran', 3), ('Manapally Madhavan Nambiar', 2), ('Manapally', 2), ('Anuradha', 2), ('Justice Menon', 2), ('Poovalli Induchoodan', 1), ('Justice Maranchery Karunakara Menon', 1), ('DYSP Sankaranarayanan', 1), ('Manapally Sudheeran', 1), ('Saikumar', 1), ('Ramakrishnan', 1), ('Moopil Nair', 1), ('Nambiar', 1), ('Aishwarya', 1), ('Mooppil Nair', 1), ('Kanaka', 1), ('Chandrabhanu', 1), ('Jayakrishnan', 1), ('Raman Nair', 1), ('Nandagopal Maarar', 1)]\n",
      "\n",
      "[('Kid', 31), ('Charley', 17), ('Brainy', 6), ('Moran', 5), ('Moose Moran', 3), ('Nellie', 3), ('Brainy Baxter', 1), ('Oxford Charley', 1), ('Nellie Thursday', 1), ('Oxford', 1), ('Henry', 1)]\n",
      "\n",
      "[('Lindy', 7), ('Azaria', 4), ('Michael', 3), ('Michael Chamberlain', 1), ('Chamberlains', 1)]\n",
      "\n",
      "[('Thomas', 14), ('Baldwin', 5), ('Kate', 4), ('Alex Thomas', 2), ('Jack Baldwin', 2), ('Stevens', 2), ('Alex', 1), ('Kate Crawford', 1), ('Crawford', 1), ('Vaughan Stevens', 1), ('Agent Thomas', 1), ('Steven', 1)]\n",
      "\n",
      "[('Dahlia', 21), ('Cecilia', 19), ('Natasha', 11), ('Kyle', 7), ('Veeck', 7), ('Murray', 4), ('Rimsky', 1), ('Natasha Rimsky', 1)]\n",
      "\n",
      "[('Hannah', 15), ('Dominic', 14), ('Miss Lombardo', 5), ('Mickey', 1)]\n",
      "\n",
      "[('John Doe', 10), ('Mitchell', 7), ('Norton', 7), ('Willoughby', 6), ('Doe', 2), ('Ann Mitchell', 1), ('Henry Connell', 1), ('John Willoughby', 1), ('Edward Arnold', 1), ('Hanson', 1), ('Connell', 1)]\n",
      "\n",
      "[('Woody', 4), ('Buzz', 3)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44659/3263213075.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['characters'] = df['plot_summary'].apply(extract_characters)\n"
     ]
    }
   ],
   "source": [
    "tagger = SequenceTagger.load('ner')\n",
    "\n",
    "def extract_characters(summary: str):\n",
    "\n",
    "    # Extract and tag senteces from summaries\n",
    "    sentences = sent_tokenize(summary)\n",
    "    tagged_sentences = [Sentence(sent) for sent in sentences]\n",
    "    tagger.predict(tagged_sentences)\n",
    "\n",
    "    # Extract all characters from the tagged sentences\n",
    "    entities = [entity for sent in tagged_sentences for entity in sent.to_dict(tag_type='ner')['entities']]\n",
    "    characters = [entity['text'] for entity in entities if entity['labels'][0]['value'] == 'PER']\n",
    "\n",
    "    # Remove punctuation and order names\n",
    "    characters = [name.translate(str.maketrans('', '', string.punctuation)) for name in characters]\n",
    "    ordered_characters = Counter(characters).most_common()\n",
    "\n",
    "    return ordered_characters\n",
    "\n",
    "df['characters'] = df['plot_summary'].apply(extract_characters)\n",
    "\n",
    "for ind in range(10):\n",
    "    print()\n",
    "    print(df.iloc[ind]['characters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42303"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(plot_summaries)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "senswiss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
