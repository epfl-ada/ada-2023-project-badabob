{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from helpers import *\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Historical Timeline\n",
    "In our analysis we want to see how representation of women in american movies might be impacted by historical events. We therefore need to retrieve a history timeline. We decided to use the timeline on https://www.history.com/topics/womens-history/womens-history-us-timeline since it contains major events related to women's history in the US."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully accessed https://www.history.com/topics/womens-history/womens-history-us-timeline\n",
      "Timeline saved in DATA/timeline.csv\n"
     ]
    }
   ],
   "source": [
    "get_history_timeline()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Complementing the dataset after 2010\n",
    "The provided dataset does not contain information on recent movies. We thus decided to complement it using IMDB data to be able to also perform our analysis in recent years. We have two main datasets to complete: the movie dataset and the character dataset. To do so, we used the data available on https://datasets.imdbws.com/ and the library Cinemagoer that can retrieve information on IMDB."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A) Complementing movie data\n",
    "To complete the movie dataset we used the following folders need to be downloaded from https://datasets.imdbws.com/, unzipped and placed in the /DATA folder:\n",
    "- title.basics.tsv.gz\n",
    "- title.akas.tsv.gz\n",
    "\n",
    "However, these files are missing a lot information that we need for our analysis (plot summaries, countries, languages). We will therefore also use the library Cinemagoer to retrieve these information. In order to not have too many useless requests to IMDB through Cinemagoer, we use the datasets title.basics and titles.akas to get a list of ID of movies we are interested in."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucil\\AppData\\Local\\Temp\\ipykernel_30584\\1877156867.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  titles_dataset = pd.read_csv('DATA/title.basics.tsv/data.tsv', sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "titles_dataset = pd.read_csv('DATA/title.basics.tsv/data.tsv', sep='\\t')\n",
    "movie_IDs = filter_titles_IDs(titles_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204389\n"
     ]
    }
   ],
   "source": [
    "print(len(movie_IDs)) # we still have 204'389"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Taking all of these movies from IMDB would take too much time. These IDs contain movies from a lot of different countries and we are only interested in american movies. We do not have the 'country' information in the downloaded datasets but we do have the 'original title' and the 'american title' in the title.akas dataset. We will use this dataset to find movies in which the original title is the same as the american one. Thus we can already remove some movies that we know are probably not american. We will of course keep a lot of non-american movies, but we can filter those out later."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucil\\AppData\\Local\\Temp\\ipykernel_30584\\1798172178.py:1: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  titles_akas_dataset = pd.read_csv('DATA/title.akas.tsv/data.tsv', sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "titles_akas_dataset = pd.read_csv('DATA/title.akas.tsv/data.tsv', sep='\\t')\n",
    "original_titles = titles_akas_dataset[titles_akas_dataset['isOriginalTitle']==1]['title']\n",
    "# get all only the lines where the title is the same as the original title\n",
    "titles_akas_dataset_filtered = titles_akas_dataset[titles_akas_dataset['title'].isin(original_titles)]\n",
    "# get only the movies where the US title is the same as the original title\n",
    "titles_akas_dataset_filtered = titles_akas_dataset_filtered[titles_akas_dataset_filtered['region'] == 'US']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39595\n"
     ]
    }
   ],
   "source": [
    "# get only IDs that are in both datasets\n",
    "common_ids = titles_akas_dataset_filtered[titles_akas_dataset_filtered['titleId'].isin(movie_IDs)]\n",
    "common_ids = common_ids['titleId'].drop_duplicates()\n",
    "print(len(common_ids)) # 39'595 movies left"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will now retrieve information of these 39'595 movies directly from IMDB using Cinemagoer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "!! THE FOLLOWING CELL TAKES A LONG TIME TO RUN !!\n",
    "Since it has already been run once and the data was saved, there is no need to run it anymore and it is thus commented."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get_IMDB_movies_data(common_ids)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "IMDB_movie_data = pd.read_csv('DATA/IMDB_movies_2010-2022.csv')\n",
    "IMDB_movie_data_filtered = filter_IMDB_movie_dataset(movie_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "         IMDB_ID              name  release_date  \\\n1      tt0112502           Bigfoot          2017   \n2      tt0172182        Blood Type          2018   \n3      tt0195933         Mysteries          2019   \n4      tt0293429     Mortal Kombat          2021   \n5      tt0297400         Snowblind          2015   \n...          ...               ...           ...   \n1756  tt10544094          The Cold          2019   \n1757  tt10544554  Mechanical Heart          2018   \n1760  tt10545182            Zealot          2019   \n1764  tt10547804       The 27 Club          2020   \n1765  tt10548502          Saturday          2020   \n\n                               languages                    countries  \\\n1                            ['English']            ['United States']   \n2                            ['English']            ['United States']   \n3                            ['English']            ['United States']   \n4     ['English', 'Japanese', 'Chinese']            ['United States']   \n5                            ['English']  ['United States', 'Canada']   \n...                                  ...                          ...   \n1756                         ['English']            ['United States']   \n1757                         ['English']            ['United States']   \n1760                         ['English']            ['United States']   \n1764                         ['English']            ['United States']   \n1765                         ['English']            ['United States']   \n\n                                                  genre  \\\n1                                ['Horror', 'Thriller']   \n2                        ['Comedy', 'Drama', 'Mystery']   \n3                                                   NaN   \n4     ['Action', 'Adventure', 'Fantasy', 'Sci-Fi', '...   \n5                                    ['Crime', 'Drama']   \n...                                                 ...   \n1756                                          ['Drama']   \n1757                                ['Comedy', 'Drama']   \n1760                                         ['Horror']   \n1764                                         ['Comedy']   \n1765                                         ['Comedy']   \n\n                                           plot_summary  \n1     ['A story of a man who, after having been thro...  \n2     ['During a frantic police car chase, a fleeing...  \n3                                                   NaN  \n4     [\"MMA fighter Cole Young seeks out Earth's gre...  \n5     ['Revealing the entrepreneurial ingenuity, par...  \n...                                                 ...  \n1756  ['Four suburban young adults are trapped toget...  \n1757  ['An aging stage actor loses his voice in an a...  \n1760                                                NaN  \n1764  ['When indie pop sensation Imogen Wright belie...  \n1765  [\"Michael finally get a day off from his job, ...  \n\n[1026 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB_ID</th>\n      <th>name</th>\n      <th>release_date</th>\n      <th>languages</th>\n      <th>countries</th>\n      <th>genre</th>\n      <th>plot_summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>tt0112502</td>\n      <td>Bigfoot</td>\n      <td>2017</td>\n      <td>['English']</td>\n      <td>['United States']</td>\n      <td>['Horror', 'Thriller']</td>\n      <td>['A story of a man who, after having been thro...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tt0172182</td>\n      <td>Blood Type</td>\n      <td>2018</td>\n      <td>['English']</td>\n      <td>['United States']</td>\n      <td>['Comedy', 'Drama', 'Mystery']</td>\n      <td>['During a frantic police car chase, a fleeing...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tt0195933</td>\n      <td>Mysteries</td>\n      <td>2019</td>\n      <td>['English']</td>\n      <td>['United States']</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tt0293429</td>\n      <td>Mortal Kombat</td>\n      <td>2021</td>\n      <td>['English', 'Japanese', 'Chinese']</td>\n      <td>['United States']</td>\n      <td>['Action', 'Adventure', 'Fantasy', 'Sci-Fi', '...</td>\n      <td>[\"MMA fighter Cole Young seeks out Earth's gre...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>tt0297400</td>\n      <td>Snowblind</td>\n      <td>2015</td>\n      <td>['English']</td>\n      <td>['United States', 'Canada']</td>\n      <td>['Crime', 'Drama']</td>\n      <td>['Revealing the entrepreneurial ingenuity, par...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1756</th>\n      <td>tt10544094</td>\n      <td>The Cold</td>\n      <td>2019</td>\n      <td>['English']</td>\n      <td>['United States']</td>\n      <td>['Drama']</td>\n      <td>['Four suburban young adults are trapped toget...</td>\n    </tr>\n    <tr>\n      <th>1757</th>\n      <td>tt10544554</td>\n      <td>Mechanical Heart</td>\n      <td>2018</td>\n      <td>['English']</td>\n      <td>['United States']</td>\n      <td>['Comedy', 'Drama']</td>\n      <td>['An aging stage actor loses his voice in an a...</td>\n    </tr>\n    <tr>\n      <th>1760</th>\n      <td>tt10545182</td>\n      <td>Zealot</td>\n      <td>2019</td>\n      <td>['English']</td>\n      <td>['United States']</td>\n      <td>['Horror']</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1764</th>\n      <td>tt10547804</td>\n      <td>The 27 Club</td>\n      <td>2020</td>\n      <td>['English']</td>\n      <td>['United States']</td>\n      <td>['Comedy']</td>\n      <td>['When indie pop sensation Imogen Wright belie...</td>\n    </tr>\n    <tr>\n      <th>1765</th>\n      <td>tt10548502</td>\n      <td>Saturday</td>\n      <td>2020</td>\n      <td>['English']</td>\n      <td>['United States']</td>\n      <td>['Comedy']</td>\n      <td>[\"Michael finally get a day off from his job, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1026 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMDB_movie_data_filtered"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now have a datasets containing all the needed information on movies from 2010-2022. We just need to merge it with the provided dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "provided_data = pd.read_csv('DATA/provided_dataset_cleaned') # TODO: CHANGE WITH VARIABLE NAME\n",
    "# change the release date to just the year to be able to merge more easily and convert it to the same format of the other df\n",
    "provided_data['release_date'] = provided_data['release_date'].str[:4].astype(int)\n",
    "# country and languages are not needed anymore\n",
    "provided_data = provided_data.drop(columns=['languages', 'countries'])\n",
    "IMDB_movie_data_filtered = IMDB_movie_data.drop(columns=['languages', 'countries'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# merge IMDB and provided dataset\n",
    "movie_data = pd.merge(provided_data, IMDB_movie_data_filtered, on=['name', 'release_date'], how='outer').copy()\n",
    "duplicated_cols = ['plot_summary', 'genre']\n",
    "movie_data = remove_duplicated_columns(movie_data, duplicated_cols)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "movie_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now have a data sets containing movies until 2022 that is ready for our analysis!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### B) Complementing characters' data\n",
    "To complete the character dataset the following folders need to be downloaded from https://datasets.imdbws.com/, unzipped and placed in the /DATA folder:\n",
    "- title.principals.tsv.gz\n",
    "- name.basics.tsv.gz"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mParserError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[69], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# construct the database for character\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m characters_data \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mDATA/title.principals.tsv/data.tsv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;130;43;01m\\t\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m IMDB_ids \u001B[38;5;241m=\u001B[39m movie_data_filtered[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIMDB_ID\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      4\u001B[0m characters_data_filtered \u001B[38;5;241m=\u001B[39m filter_IMDB_character_dataset(characters_data, IMDB_ids)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m    899\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    900\u001B[0m     dialect,\n\u001B[0;32m    901\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    908\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[0;32m    909\u001B[0m )\n\u001B[0;32m    910\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 912\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:583\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    580\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[0;32m    582\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parser:\n\u001B[1;32m--> 583\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1704\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m   1697\u001B[0m nrows \u001B[38;5;241m=\u001B[39m validate_integer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnrows\u001B[39m\u001B[38;5;124m\"\u001B[39m, nrows)\n\u001B[0;32m   1698\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1699\u001B[0m     \u001B[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001B[39;00m\n\u001B[0;32m   1700\u001B[0m     (\n\u001B[0;32m   1701\u001B[0m         index,\n\u001B[0;32m   1702\u001B[0m         columns,\n\u001B[0;32m   1703\u001B[0m         col_dict,\n\u001B[1;32m-> 1704\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[attr-defined]\u001B[39;49;00m\n\u001B[0;32m   1705\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnrows\u001B[49m\n\u001B[0;32m   1706\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1707\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m   1708\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001B[0m, in \u001B[0;36mCParserWrapper.read\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m    232\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    233\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlow_memory:\n\u001B[1;32m--> 234\u001B[0m         chunks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_low_memory\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    235\u001B[0m         \u001B[38;5;66;03m# destructive to chunks\u001B[39;00m\n\u001B[0;32m    236\u001B[0m         data \u001B[38;5;241m=\u001B[39m _concatenate_chunks(chunks)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:814\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:875\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._read_rows\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:850\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:861\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ada\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:2029\u001B[0m, in \u001B[0;36mpandas._libs.parsers.raise_parser_error\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mParserError\u001B[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "# load characters info\n",
    "characters_data = pd.read_csv('DATA/title.principals.tsv/data.tsv', sep='\\t')\n",
    "IMDB_ids = IMDB_movie_data_filtered['IMDB_ID']\n",
    "# only keep characters of the filtered movies\n",
    "characters_data_filtered = filter_IMDB_character_dataset(characters_data, IMDB_ids)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load actors info\n",
    "actors_data = pd.read_csv('DATA/name.basics.tsv/data.tsv', sep='\\t')\n",
    "# remove useless columns\n",
    "actors_data = actors_data.drop(columns=['deathYear', 'primaryProfession', 'knownForTitles'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now need to merge all the information we have on the characters and the actors. There are some information we still need to add to the dataframe: release date, actor age, movie name. These will be added by merging with the movie dataset created above."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# merge actor data and movie data on character data\n",
    "IMDB_characters_data = merge_datasets_characters(characters_data_filtered, actors_data, IMDB_movie_data_filtered)\n",
    "IMDB_characters_data.loc[IMDB_characters_data['character_name'] == '\\\\N', 'character_name'] = None\n",
    "IMDB_characters_data['release_date'] = IMDB_characters_data['release_date'].astype(float) #so that it's the same type as the provided data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "         IMDB_ID actor_IMDB_ID   character_name actor_gender  \\\n0      tt0172182     nm0182661          Bum Joe            M   \n1      tt0172182     nm0500098         Tiffanie            F   \n2      tt0172182     nm0090981             Chad            M   \n3      tt0172182     nm0001730         Mrs. Dow            F   \n4      tt0293429     nm1167985       Cole Young            M   \n...          ...           ...              ...          ...   \n3123  tt10548502    nm10791665  Jehovah Witness            M   \n3124  tt10548502    nm10437154            Black            M   \n3125  tt10548502    nm10791663           Roland            M   \n3126  tt10548502     nm8820193             Earl            M   \n3127  tt10548502     nm9656262           Denise            F   \n\n            actor_name  actor_birthday           name  release_date  actor_age  \n0       Nicolas Coster          1933.0     Blood Type          2018       85.0  \n1         Hudson Leick          1969.0     Blood Type          2018       49.0  \n2     Wolfgang Bodison          1966.0     Blood Type          2018       52.0  \n3      Deborah Shelton          1948.0     Blood Type          2018       70.0  \n4            Lewis Tan             NaN  Mortal Kombat          2021        NaN  \n...                ...             ...            ...           ...        ...  \n3123       D.J. Gibson             NaN       Saturday          2020        NaN  \n3124  Rodney H. Glover             NaN       Saturday          2020        NaN  \n3125    Deitrick Greer             NaN       Saturday          2020        NaN  \n3126    Cecil M. Henry             NaN       Saturday          2020        NaN  \n3127      Sha'ron Lynn             NaN       Saturday          2020        NaN  \n\n[3128 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB_ID</th>\n      <th>actor_IMDB_ID</th>\n      <th>character_name</th>\n      <th>actor_gender</th>\n      <th>actor_name</th>\n      <th>actor_birthday</th>\n      <th>name</th>\n      <th>release_date</th>\n      <th>actor_age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tt0172182</td>\n      <td>nm0182661</td>\n      <td>Bum Joe</td>\n      <td>M</td>\n      <td>Nicolas Coster</td>\n      <td>1933.0</td>\n      <td>Blood Type</td>\n      <td>2018</td>\n      <td>85.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>tt0172182</td>\n      <td>nm0500098</td>\n      <td>Tiffanie</td>\n      <td>F</td>\n      <td>Hudson Leick</td>\n      <td>1969.0</td>\n      <td>Blood Type</td>\n      <td>2018</td>\n      <td>49.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tt0172182</td>\n      <td>nm0090981</td>\n      <td>Chad</td>\n      <td>M</td>\n      <td>Wolfgang Bodison</td>\n      <td>1966.0</td>\n      <td>Blood Type</td>\n      <td>2018</td>\n      <td>52.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tt0172182</td>\n      <td>nm0001730</td>\n      <td>Mrs. Dow</td>\n      <td>F</td>\n      <td>Deborah Shelton</td>\n      <td>1948.0</td>\n      <td>Blood Type</td>\n      <td>2018</td>\n      <td>70.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tt0293429</td>\n      <td>nm1167985</td>\n      <td>Cole Young</td>\n      <td>M</td>\n      <td>Lewis Tan</td>\n      <td>NaN</td>\n      <td>Mortal Kombat</td>\n      <td>2021</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3123</th>\n      <td>tt10548502</td>\n      <td>nm10791665</td>\n      <td>Jehovah Witness</td>\n      <td>M</td>\n      <td>D.J. Gibson</td>\n      <td>NaN</td>\n      <td>Saturday</td>\n      <td>2020</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3124</th>\n      <td>tt10548502</td>\n      <td>nm10437154</td>\n      <td>Black</td>\n      <td>M</td>\n      <td>Rodney H. Glover</td>\n      <td>NaN</td>\n      <td>Saturday</td>\n      <td>2020</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3125</th>\n      <td>tt10548502</td>\n      <td>nm10791663</td>\n      <td>Roland</td>\n      <td>M</td>\n      <td>Deitrick Greer</td>\n      <td>NaN</td>\n      <td>Saturday</td>\n      <td>2020</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3126</th>\n      <td>tt10548502</td>\n      <td>nm8820193</td>\n      <td>Earl</td>\n      <td>M</td>\n      <td>Cecil M. Henry</td>\n      <td>NaN</td>\n      <td>Saturday</td>\n      <td>2020</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3127</th>\n      <td>tt10548502</td>\n      <td>nm9656262</td>\n      <td>Denise</td>\n      <td>F</td>\n      <td>Sha'ron Lynn</td>\n      <td>NaN</td>\n      <td>Saturday</td>\n      <td>2020</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>3128 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMDB_characters_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can now merge this IMDB character dataset with the provided character dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#provided_characters = character_metadata_noNA_genderYear_personnas #TODO: replace by variable name\n",
    "provided_characters = pd.read_csv('DATA/US_movies_with_movie_names')\n",
    "#change birthday into birth year\n",
    "provided_characters['actor_birthday'] = provided_characters['actor_birthday'].str[:4].astype(float)\n",
    "provided_characters['release_date'] = provided_characters['release_date'].str[:4].astype(float)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "#first put everything in lower case\n",
    "provided_characters['character_name'] = name_to_lowercase(provided_characters, 'character_name')\n",
    "provided_characters['actor_name'] = name_to_lowercase(provided_characters, 'actor_name')\n",
    "IMDB_characters_data['character_name'] = name_to_lowercase(IMDB_characters_data, 'character_name')\n",
    "IMDB_characters_data['actor_name'] = name_to_lowercase(IMDB_characters_data, 'actor_name')\n",
    "# merge datasets\n",
    "characters_data = pd.merge(provided_characters, IMDB_characters_data, on=['name', 'character_name', 'actor_name', 'release_date'], how='outer').copy()\n",
    "# remove columns that were duplicated\n",
    "duplicated_cols = ['actor_birthday', 'actor_gender', 'actor_age']\n",
    "characters_data= remove_duplicated_columns(characters_data, duplicated_cols)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "        wikipedia_ID freebase_ID  release_date              character_name  \\\n0           975900.0   /m/03vyhn        2001.0                    akooshay   \n1           975900.0   /m/03vyhn        2001.0  lieutenant melanie ballard   \n2           975900.0   /m/03vyhn        2001.0         desolation williams   \n3           975900.0   /m/03vyhn        2001.0          sgt jericho butler   \n4           975900.0   /m/03vyhn        2001.0             bashira kincaid   \n...              ...         ...           ...                         ...   \n398294           NaN         NaN        2020.0             jehovah witness   \n398295           NaN         NaN        2020.0                       black   \n398296           NaN         NaN        2020.0                      roland   \n398297           NaN         NaN        2020.0                        earl   \n398298           NaN         NaN        2020.0                      denise   \n\n        actor_birthday actor_gender  actor_height actor_ethnicity  \\\n0               1958.0            F         1.620             NaN   \n1               1974.0            F         1.780      /m/044038p   \n2               1969.0            M         1.727         /m/0x67   \n3               1967.0            M         1.750             NaN   \n4               1977.0            F         1.650             NaN   \n...                ...          ...           ...             ...   \n398294             NaN            M           NaN             NaN   \n398295             NaN            M           NaN             NaN   \n398296             NaN            M           NaN             NaN   \n398297             NaN            M           NaN             NaN   \n398298             NaN            F           NaN             NaN   \n\n                actor_name  actor_age freebase_character_actor_mapID  \\\n0           wanda de jesus       42.0                     /m/0bgchxw   \n1       natasha henstridge       27.0                      /m/0jys3m   \n2                 ice cube       32.0                      /m/0jys3g   \n3            jason statham       33.0                     /m/02vchl6   \n4              clea duvall       23.0                     /m/02vbb3r   \n...                    ...        ...                            ...   \n398294         d.j. gibson        NaN                            NaN   \n398295    rodney h. glover        NaN                            NaN   \n398296      deitrick greer        NaN                            NaN   \n398297      cecil m. henry        NaN                            NaN   \n398298        sha'ron lynn        NaN                            NaN   \n\n       freebase_character_ID freebase_actor_ID personnas            name  \\\n0                 /m/0bgcj3x        /m/03wcfv7       NaN  Ghosts of Mars   \n1                 /m/0bgchn4         /m/0346l4       NaN  Ghosts of Mars   \n2                 /m/0bgchn_        /m/01vw26l       NaN  Ghosts of Mars   \n3                 /m/0bgchnq         /m/034hyc       NaN  Ghosts of Mars   \n4                 /m/0bgchp9         /m/01y9xg       NaN  Ghosts of Mars   \n...                      ...               ...       ...             ...   \n398294                   NaN               NaN       NaN        Saturday   \n398295                   NaN               NaN       NaN        Saturday   \n398296                   NaN               NaN       NaN        Saturday   \n398297                   NaN               NaN       NaN        Saturday   \n398298                   NaN               NaN       NaN        Saturday   \n\n           IMDB_ID actor_IMDB_ID  \n0              NaN           NaN  \n1              NaN           NaN  \n2              NaN           NaN  \n3              NaN           NaN  \n4              NaN           NaN  \n...            ...           ...  \n398294  tt10548502    nm10791665  \n398295  tt10548502    nm10437154  \n398296  tt10548502    nm10791663  \n398297  tt10548502     nm8820193  \n398298  tt10548502     nm9656262  \n\n[398299 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>wikipedia_ID</th>\n      <th>freebase_ID</th>\n      <th>release_date</th>\n      <th>character_name</th>\n      <th>actor_birthday</th>\n      <th>actor_gender</th>\n      <th>actor_height</th>\n      <th>actor_ethnicity</th>\n      <th>actor_name</th>\n      <th>actor_age</th>\n      <th>freebase_character_actor_mapID</th>\n      <th>freebase_character_ID</th>\n      <th>freebase_actor_ID</th>\n      <th>personnas</th>\n      <th>name</th>\n      <th>IMDB_ID</th>\n      <th>actor_IMDB_ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>975900.0</td>\n      <td>/m/03vyhn</td>\n      <td>2001.0</td>\n      <td>akooshay</td>\n      <td>1958.0</td>\n      <td>F</td>\n      <td>1.620</td>\n      <td>NaN</td>\n      <td>wanda de jesus</td>\n      <td>42.0</td>\n      <td>/m/0bgchxw</td>\n      <td>/m/0bgcj3x</td>\n      <td>/m/03wcfv7</td>\n      <td>NaN</td>\n      <td>Ghosts of Mars</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>975900.0</td>\n      <td>/m/03vyhn</td>\n      <td>2001.0</td>\n      <td>lieutenant melanie ballard</td>\n      <td>1974.0</td>\n      <td>F</td>\n      <td>1.780</td>\n      <td>/m/044038p</td>\n      <td>natasha henstridge</td>\n      <td>27.0</td>\n      <td>/m/0jys3m</td>\n      <td>/m/0bgchn4</td>\n      <td>/m/0346l4</td>\n      <td>NaN</td>\n      <td>Ghosts of Mars</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>975900.0</td>\n      <td>/m/03vyhn</td>\n      <td>2001.0</td>\n      <td>desolation williams</td>\n      <td>1969.0</td>\n      <td>M</td>\n      <td>1.727</td>\n      <td>/m/0x67</td>\n      <td>ice cube</td>\n      <td>32.0</td>\n      <td>/m/0jys3g</td>\n      <td>/m/0bgchn_</td>\n      <td>/m/01vw26l</td>\n      <td>NaN</td>\n      <td>Ghosts of Mars</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>975900.0</td>\n      <td>/m/03vyhn</td>\n      <td>2001.0</td>\n      <td>sgt jericho butler</td>\n      <td>1967.0</td>\n      <td>M</td>\n      <td>1.750</td>\n      <td>NaN</td>\n      <td>jason statham</td>\n      <td>33.0</td>\n      <td>/m/02vchl6</td>\n      <td>/m/0bgchnq</td>\n      <td>/m/034hyc</td>\n      <td>NaN</td>\n      <td>Ghosts of Mars</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>975900.0</td>\n      <td>/m/03vyhn</td>\n      <td>2001.0</td>\n      <td>bashira kincaid</td>\n      <td>1977.0</td>\n      <td>F</td>\n      <td>1.650</td>\n      <td>NaN</td>\n      <td>clea duvall</td>\n      <td>23.0</td>\n      <td>/m/02vbb3r</td>\n      <td>/m/0bgchp9</td>\n      <td>/m/01y9xg</td>\n      <td>NaN</td>\n      <td>Ghosts of Mars</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>398294</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020.0</td>\n      <td>jehovah witness</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>d.j. gibson</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Saturday</td>\n      <td>tt10548502</td>\n      <td>nm10791665</td>\n    </tr>\n    <tr>\n      <th>398295</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020.0</td>\n      <td>black</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>rodney h. glover</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Saturday</td>\n      <td>tt10548502</td>\n      <td>nm10437154</td>\n    </tr>\n    <tr>\n      <th>398296</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020.0</td>\n      <td>roland</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>deitrick greer</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Saturday</td>\n      <td>tt10548502</td>\n      <td>nm10791663</td>\n    </tr>\n    <tr>\n      <th>398297</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020.0</td>\n      <td>earl</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>cecil m. henry</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Saturday</td>\n      <td>tt10548502</td>\n      <td>nm8820193</td>\n    </tr>\n    <tr>\n      <th>398298</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020.0</td>\n      <td>denise</td>\n      <td>NaN</td>\n      <td>F</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>sha'ron lynn</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Saturday</td>\n      <td>tt10548502</td>\n      <td>nm9656262</td>\n    </tr>\n  </tbody>\n</table>\n<p>398299 rows × 17 columns</p>\n</div>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters_data"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
