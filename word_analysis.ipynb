{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of words in summaries to determine character actions [Work in progress]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of all the abbreviations https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "The verbs are given by :\n",
    "- VB\n",
    "- VBD\n",
    "- VBG\n",
    "- VBN\n",
    "- VBP\n",
    "- VBZ\n",
    "\n",
    "The adjectives are given by :\n",
    "\n",
    "- JJ\n",
    "- JJR\n",
    "- JJS\n",
    "\n",
    "The nouns are given by:\n",
    "- NN\n",
    "- NNS\n",
    "- NNP\n",
    "- NNPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline to extract verbs, adjectives and nouns from the plot summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stopwords appear very frequently in the text they mask the important words. We therefore remove them from the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Once this function is finalized move it to helpers.py file (and comment it correctly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs (pickle and csv) can be downloaded at https://drive.switch.ch/index.php/s/U5ntGAtMkXWi9yn. They are not pushed onto the repository as they are too large (>100MB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning genders to characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of missing genders is reasonable, it is therefore not necessary to predict them for the rest of the analysis. If it later comes out that this is required packages such as gender-guesser (https://pypi.org/project/gender-guesser/) can be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of missing character's name is close to 25% so we will be able to perform our analysis only on 75% of the characters in our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the summary, extract the characters that appear and matches them with the character_data and associate the gender of the actor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now \"scans\" each summary for each character (perfect match or not) and associate them the previous and folllowing 3 words in the summmary, these words will be analyzed later on)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last step, take the words extracted at the previous step and classify them into verbs nouns and adjectives, and depending on the actor's gender, append them to the designated dictionnary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "characters_data=pd.read_csv('DATA/characters_data.csv',low_memory=False)\n",
    "movie_data=pd.read_csv('DATA/movie_data.csv',low_memory=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Count number of nans in gender column\n",
    "missing_gender_percentage = 100 * characters_data['actor_gender'].isna().sum() / len(characters_data.index)\n",
    "print(f\"Number of missing genders: {missing_gender_percentage:.2f}%\")\n",
    "# Count number of nans in character name column\n",
    "missing_names_percentage = 100 * characters_data['character_name'].isna().sum() / len(characters_data.index)\n",
    "print(f\"Number of missing character names: {missing_names_percentage:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# drop the characters with missing character names and actors gender so we can determine if characters are F/M\n",
    "characters_noNA = characters_data.dropna(subset=[\"character_name\", \"actor_gender\"])\n",
    "# drop movies with missing summaries\n",
    "movie_noNA = movie_data.dropna(subset=[\"plot_summary\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "         IMDB_ID  wikipedia_ID freebase_ID  box_office_revenue  runtime  \\\n0      tt0228333      975900.0   /m/03vyhn          14010832.0     98.0   \n5      tt0119548     6631279.0   /m/0gffwj                 NaN     93.0   \n6      tt0058331       77856.0    /m/0kcn7         102272727.0    139.0   \n10     tt0892904    21926710.0  /m/05p45cv                 NaN     82.0   \n12     tt0255819      156558.0   /m/014k4y          29381649.0    123.0   \n...          ...           ...         ...                 ...      ...   \n53602  tt9908448           NaN         NaN                 NaN      NaN   \n53603  tt9908592           NaN         NaN                 NaN      NaN   \n53605  tt9910648           NaN         NaN                 NaN      NaN   \n53608  tt9913288           NaN         NaN                 NaN      NaN   \n53609  tt9914522           NaN         NaN                 NaN      NaN   \n\n                                                  name  release_date  \\\n0                                       Ghosts of Mars        2001.0   \n5                                          Little city        1997.0   \n6                                         Mary Poppins        1964.0   \n10                                       White on Rice        2009.0   \n12                                            Baby Boy        2001.0   \n...                                                ...           ...   \n53602                                The Bells of Hell        2018.0   \n53603                            Filmmakers Unite (FU)        2017.0   \n53605  The Good Americans: One Revolution, Two Nations        2021.0   \n53608                                          Letters        2020.0   \n53609                           The Holden Family Plan        2019.0   \n\n                                                   genre  \\\n0      ['Thriller', 'Adventure', 'Horror', 'Action', ...   \n5      ['Comedy', 'Romance Film', 'Drama', 'Romantic ...   \n6      ['Musical', \"Children's/Family\", 'Drama', 'Com...   \n10                                                    []   \n12                            ['Drama', 'Coming of age']   \n...                                                  ...   \n53602                                                 []   \n53603                                                 []   \n53605                                                 []   \n53608                                                 []   \n53609                                                 []   \n\n                                            plot_summary  \n0      Set in the second half of the 22nd century, th...  \n5      Adam, a San Francisco-based artist who works a...  \n6      The film opens with Mary Poppins  perched in a...  \n10     [\"Forty-year-old Jimmy is growing up--or at le...  \n12     A young 20-year-old named Jody  lives with his...  \n...                                                  ...  \n53602  ['An alcoholic newlywed wife spends three days...  \n53603  ['Curated by Jay Rosenblatt and Ellen Bruno, F...  \n53605  ['Størmerlige Films is making a feature-length...  \n53608  [\"Charlie Porter is an ordinary man. He leads ...  \n53609  [\"When Mackenzie Holden's sister and brother i...  \n\n[34764 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB_ID</th>\n      <th>wikipedia_ID</th>\n      <th>freebase_ID</th>\n      <th>box_office_revenue</th>\n      <th>runtime</th>\n      <th>name</th>\n      <th>release_date</th>\n      <th>genre</th>\n      <th>plot_summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tt0228333</td>\n      <td>975900.0</td>\n      <td>/m/03vyhn</td>\n      <td>14010832.0</td>\n      <td>98.0</td>\n      <td>Ghosts of Mars</td>\n      <td>2001.0</td>\n      <td>['Thriller', 'Adventure', 'Horror', 'Action', ...</td>\n      <td>Set in the second half of the 22nd century, th...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>tt0119548</td>\n      <td>6631279.0</td>\n      <td>/m/0gffwj</td>\n      <td>NaN</td>\n      <td>93.0</td>\n      <td>Little city</td>\n      <td>1997.0</td>\n      <td>['Comedy', 'Romance Film', 'Drama', 'Romantic ...</td>\n      <td>Adam, a San Francisco-based artist who works a...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>tt0058331</td>\n      <td>77856.0</td>\n      <td>/m/0kcn7</td>\n      <td>102272727.0</td>\n      <td>139.0</td>\n      <td>Mary Poppins</td>\n      <td>1964.0</td>\n      <td>['Musical', \"Children's/Family\", 'Drama', 'Com...</td>\n      <td>The film opens with Mary Poppins  perched in a...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>tt0892904</td>\n      <td>21926710.0</td>\n      <td>/m/05p45cv</td>\n      <td>NaN</td>\n      <td>82.0</td>\n      <td>White on Rice</td>\n      <td>2009.0</td>\n      <td>[]</td>\n      <td>[\"Forty-year-old Jimmy is growing up--or at le...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>tt0255819</td>\n      <td>156558.0</td>\n      <td>/m/014k4y</td>\n      <td>29381649.0</td>\n      <td>123.0</td>\n      <td>Baby Boy</td>\n      <td>2001.0</td>\n      <td>['Drama', 'Coming of age']</td>\n      <td>A young 20-year-old named Jody  lives with his...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>53602</th>\n      <td>tt9908448</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>The Bells of Hell</td>\n      <td>2018.0</td>\n      <td>[]</td>\n      <td>['An alcoholic newlywed wife spends three days...</td>\n    </tr>\n    <tr>\n      <th>53603</th>\n      <td>tt9908592</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Filmmakers Unite (FU)</td>\n      <td>2017.0</td>\n      <td>[]</td>\n      <td>['Curated by Jay Rosenblatt and Ellen Bruno, F...</td>\n    </tr>\n    <tr>\n      <th>53605</th>\n      <td>tt9910648</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>The Good Americans: One Revolution, Two Nations</td>\n      <td>2021.0</td>\n      <td>[]</td>\n      <td>['Størmerlige Films is making a feature-length...</td>\n    </tr>\n    <tr>\n      <th>53608</th>\n      <td>tt9913288</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Letters</td>\n      <td>2020.0</td>\n      <td>[]</td>\n      <td>[\"Charlie Porter is an ordinary man. He leads ...</td>\n    </tr>\n    <tr>\n      <th>53609</th>\n      <td>tt9914522</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>The Holden Family Plan</td>\n      <td>2019.0</td>\n      <td>[]</td>\n      <td>[\"When Mackenzie Holden's sister and brother i...</td>\n    </tr>\n  </tbody>\n</table>\n<p>34764 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of movies that we will use in the analysis - must have summary, character name and gender\n",
    "filtered_df = movie_noNA[movie_noNA['IMDB_ID'].isin(characters_noNA['IMDB_ID'])]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "#output_characters_genders=find_characters_genders_for_all_movies(filtered_df, characters_noNA)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_characters_genders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[147], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Save output to csv\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43moutput_characters_genders\u001B[49m\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDATA/output_characters_genders.csv\u001B[39m\u001B[38;5;124m'\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'output_characters_genders' is not defined"
     ]
    }
   ],
   "source": [
    "# Save output to csv\n",
    "output_characters_genders.to_csv('DATA/output_characters_genders.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Export as pickle\n",
    "output_characters_genders.to_pickle('pickles/output_characters_genders.pickle')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_characters_genders"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "count_gender = output_characters_genders['gender'].value_counts().to_dict()\n",
    "\n",
    "print(\n",
    "    \"There are only {} movies left and with {} male characters and {} female characters.\".format(\n",
    "        len(output_characters_genders['IMDB_ID'].unique()), count_gender.get(\"M\", 0), count_gender.get(\"F\", 0)\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#output_characters_genders_context=extract_context_strings(output_characters_genders)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save result as csv\n",
    "output_characters_genders_context.to_csv('DATA/output_characters_genders_context.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save result as pickle\n",
    "output_characters_genders_context.to_pickle('pickles/output_characters_genders_context.pickle')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# Load from csv\n",
    "output_characters_genders_context=pd.read_csv('DATA/output_characters_genders_context.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "          IMDB_ID                                       plot_summary  \\\n0       tt0228333  Set second half 22nd century, film depicts Mar...   \n1       tt0228333  Set second half 22nd century, film depicts Mar...   \n2       tt0228333  Set second half 22nd century, film depicts Mar...   \n3       tt0228333  Set second half 22nd century, film depicts Mar...   \n4       tt0228333  Set second half 22nd century, film depicts Mar...   \n...           ...                                                ...   \n176329  tt9914522  [\"When Mackenzie Holden's sister brother law m...   \n176330  tt9914522  [\"When Mackenzie Holden's sister brother law m...   \n176331  tt9914522  [\"When Mackenzie Holden's sister brother law m...   \n176332  tt9914522  [\"When Mackenzie Holden's sister brother law m...   \n176333  tt9914522  [\"When Mackenzie Holden's sister brother law m...   \n\n            character_name gender  \\\n0       Sgt Jericho Butler      M   \n1          Bashira Kincaid      F   \n2         Michael Descanso      M   \n3           Big Daddy Mars      M   \n4                 Akooshay      F   \n...                    ...    ...   \n176329             Katelyn      F   \n176330              Kelsey      F   \n176331                Jade      F   \n176332                Evan      M   \n176333                Todd      M   \n\n                                         associated_words  \n0       second half 22nd humans walk surface  wearing ...  \n1       pick transport prisoner  Desolation Williams A...  \n2       Set second  22nd century film 22nd century fil...  \n3             century film depicts  planet 84 terraformed  \n4       Set second  22nd century film miners discovere...  \n...                                                   ...  \n176329                                                NaN  \n176330                                                NaN  \n176331  honeymoon Mackenzie new  Evan decision make ma...  \n176332     Mackenzie new husband  decision make regarding  \n176333                                                NaN  \n\n[176334 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMDB_ID</th>\n      <th>plot_summary</th>\n      <th>character_name</th>\n      <th>gender</th>\n      <th>associated_words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tt0228333</td>\n      <td>Set second half 22nd century, film depicts Mar...</td>\n      <td>Sgt Jericho Butler</td>\n      <td>M</td>\n      <td>second half 22nd humans walk surface  wearing ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>tt0228333</td>\n      <td>Set second half 22nd century, film depicts Mar...</td>\n      <td>Bashira Kincaid</td>\n      <td>F</td>\n      <td>pick transport prisoner  Desolation Williams A...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tt0228333</td>\n      <td>Set second half 22nd century, film depicts Mar...</td>\n      <td>Michael Descanso</td>\n      <td>M</td>\n      <td>Set second  22nd century film 22nd century fil...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tt0228333</td>\n      <td>Set second half 22nd century, film depicts Mar...</td>\n      <td>Big Daddy Mars</td>\n      <td>M</td>\n      <td>century film depicts  planet 84 terraformed</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tt0228333</td>\n      <td>Set second half 22nd century, film depicts Mar...</td>\n      <td>Akooshay</td>\n      <td>F</td>\n      <td>Set second  22nd century film miners discovere...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>176329</th>\n      <td>tt9914522</td>\n      <td>[\"When Mackenzie Holden's sister brother law m...</td>\n      <td>Katelyn</td>\n      <td>F</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>176330</th>\n      <td>tt9914522</td>\n      <td>[\"When Mackenzie Holden's sister brother law m...</td>\n      <td>Kelsey</td>\n      <td>F</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>176331</th>\n      <td>tt9914522</td>\n      <td>[\"When Mackenzie Holden's sister brother law m...</td>\n      <td>Jade</td>\n      <td>F</td>\n      <td>honeymoon Mackenzie new  Evan decision make ma...</td>\n    </tr>\n    <tr>\n      <th>176332</th>\n      <td>tt9914522</td>\n      <td>[\"When Mackenzie Holden's sister brother law m...</td>\n      <td>Evan</td>\n      <td>M</td>\n      <td>Mackenzie new husband  decision make regarding</td>\n    </tr>\n    <tr>\n      <th>176333</th>\n      <td>tt9914522</td>\n      <td>[\"When Mackenzie Holden's sister brother law m...</td>\n      <td>Todd</td>\n      <td>M</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>176334 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_characters_genders_context"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Movies: 100%|██████████| 176334/176334 [18:35<00:00, 158.04it/s] \n",
      "                                                                            \r"
     ]
    }
   ],
   "source": [
    "verbs, adjs, nouns, chunks = extract_words(output_characters_genders_context, \"IMDB_ID\", \"character_name\",\"associated_words\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "# Create DataFrames from the lists\n",
    "verbs_df = pd.DataFrame(verbs, columns=['IMDB_ID', 'character_name', 'Verbs'])\n",
    "adjs_df = pd.DataFrame(adjs, columns=['IMDB_ID', 'character_name', 'Adjectives'])\n",
    "nouns_df = pd.DataFrame(nouns, columns=['IMDB_ID', 'character_name', 'Nouns'])\n",
    "chunks_df = pd.DataFrame(chunks, columns=['IMDB_ID', 'character_name', 'Chunks'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# Merge DataFrames on 'IMDB_ID' and 'character_name'\n",
    "final_df = verbs_df.merge(adjs_df, on=['IMDB_ID', 'character_name']) \\\n",
    "                    .merge(nouns_df, on=['IMDB_ID', 'character_name']) \\\n",
    "                    .merge(chunks_df, on=['IMDB_ID', 'character_name'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "              character_name  \\\n0         Sgt Jericho Butler   \n1            Bashira Kincaid   \n2           Michael Descanso   \n3             Big Daddy Mars   \n4                   Akooshay   \n...                      ...   \n45040982               Jewel   \n45040983               Jewel   \n45040984               Jewel   \n45040985               Jewel   \n45040986               Jewel   \n\n                                                      Verbs  \\\n0         [walk, wearing, sent, opened, released, posses...   \n1         [killed, returning, blame, cot, escapes, leaving]   \n2         [planet, finds, missing, discovered, discovere...   \n3                                     [planet, terraformed]   \n4                              [discovered, created, wiped]   \n...                                                     ...   \n45040982                                             [Rose]   \n45040983                                             [Rose]   \n45040984                                             [Rose]   \n45040985                                             [Rose]   \n45040986                                             [Rose]   \n\n                                                 Adjectives  \\\n0         [second, pick, disembodied, possible, Unfortun...   \n1                                                [massacre]   \n2         [second, 22nd, 22nd, doorway, ancient, Martian...   \n3                                                        []   \n4                           [second, 22nd, ancient, fierce]   \n...                                                     ...   \n45040982                                       [mysterious]   \n45040983                                       [mysterious]   \n45040984                                       [mysterious]   \n45040985                                       [mysterious]   \n45040986                                       [mysterious]   \n\n                                                      Nouns  \\\n0         [half, humans, surface, pressure, suits, team,...   \n1         [pick, transport, prisoner, Desolation, Willia...   \n2         [Set, century, film, century, film, Mars, mini...   \n3                                  [century, film, depicts]   \n4         [Set, century, film, miners, Martian, miners, ...   \n...                                                     ...   \n45040982  [letter, stalker, catalepsy, condition, condit...   \n45040983  [letter, stalker, catalepsy, condition, condit...   \n45040984  [letter, stalker, catalepsy, condition, condit...   \n45040985  [letter, stalker, catalepsy, condition, condit...   \n45040986  [letter, stalker, catalepsy, condition, condit...   \n\n                                                     Chunks  \n0         [(second, JJ), (half, NN), (22nd, CD), (humans...  \n1         [(pick, NN), (transport, NN), (prisoner, NN), ...  \n2         [[(Set, NNP)], (second, JJ), (22nd, JJ), (cent...  \n3         [(century, NN), (film, NN), (depicts, NNS), (p...  \n4         [[(Set, NNP)], (second, JJ), (22nd, JJ), (cent...  \n...                                                     ...  \n45040982  [(found, VBN), (drug, NN), (attic, JJ), (prost...  \n45040983  [(young, JJ), (couple, NN), [(Nathan, NNP)], (...  \n45040984  [(part, NN), (true, JJ), (story, NN), (gospel,...  \n45040985  [(father, RB), (introduced, VBN), (intriguing,...  \n45040986  [(letter, NN), (mysterious, JJ), (stalker, NN)...  \n\n[45040987 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>character_name</th>\n      <th>Verbs</th>\n      <th>Adjectives</th>\n      <th>Nouns</th>\n      <th>Chunks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sgt Jericho Butler</td>\n      <td>[walk, wearing, sent, opened, released, posses...</td>\n      <td>[second, pick, disembodied, possible, Unfortun...</td>\n      <td>[half, humans, surface, pressure, suits, team,...</td>\n      <td>[(second, JJ), (half, NN), (22nd, CD), (humans...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Bashira Kincaid</td>\n      <td>[killed, returning, blame, cot, escapes, leaving]</td>\n      <td>[massacre]</td>\n      <td>[pick, transport, prisoner, Desolation, Willia...</td>\n      <td>[(pick, NN), (transport, NN), (prisoner, NN), ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Michael Descanso</td>\n      <td>[planet, finds, missing, discovered, discovere...</td>\n      <td>[second, 22nd, 22nd, doorway, ancient, Martian...</td>\n      <td>[Set, century, film, century, film, Mars, mini...</td>\n      <td>[[(Set, NNP)], (second, JJ), (22nd, JJ), (cent...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Big Daddy Mars</td>\n      <td>[planet, terraformed]</td>\n      <td>[]</td>\n      <td>[century, film, depicts]</td>\n      <td>[(century, NN), (film, NN), (depicts, NNS), (p...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Akooshay</td>\n      <td>[discovered, created, wiped]</td>\n      <td>[second, 22nd, ancient, fierce]</td>\n      <td>[Set, century, film, miners, Martian, miners, ...</td>\n      <td>[[(Set, NNP)], (second, JJ), (22nd, JJ), (cent...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>45040982</th>\n      <td>Jewel</td>\n      <td>[Rose]</td>\n      <td>[mysterious]</td>\n      <td>[letter, stalker, catalepsy, condition, condit...</td>\n      <td>[(found, VBN), (drug, NN), (attic, JJ), (prost...</td>\n    </tr>\n    <tr>\n      <th>45040983</th>\n      <td>Jewel</td>\n      <td>[Rose]</td>\n      <td>[mysterious]</td>\n      <td>[letter, stalker, catalepsy, condition, condit...</td>\n      <td>[(young, JJ), (couple, NN), [(Nathan, NNP)], (...</td>\n    </tr>\n    <tr>\n      <th>45040984</th>\n      <td>Jewel</td>\n      <td>[Rose]</td>\n      <td>[mysterious]</td>\n      <td>[letter, stalker, catalepsy, condition, condit...</td>\n      <td>[(part, NN), (true, JJ), (story, NN), (gospel,...</td>\n    </tr>\n    <tr>\n      <th>45040985</th>\n      <td>Jewel</td>\n      <td>[Rose]</td>\n      <td>[mysterious]</td>\n      <td>[letter, stalker, catalepsy, condition, condit...</td>\n      <td>[(father, RB), (introduced, VBN), (intriguing,...</td>\n    </tr>\n    <tr>\n      <th>45040986</th>\n      <td>Jewel</td>\n      <td>[Rose]</td>\n      <td>[mysterious]</td>\n      <td>[letter, stalker, catalepsy, condition, condit...</td>\n      <td>[(letter, NN), (mysterious, JJ), (stalker, NN)...</td>\n    </tr>\n  </tbody>\n</table>\n<p>45040987 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# to have the genders, use that df if it is too big to merge with the character_data and save to csv\n",
    "# DO NOT RUN THAT CELL IF RUN THE PREVIOUS ONE DOES BECAUSE THE GENDER COLUMN WILL BE DUPLICATED\n",
    "# max l'a run lol\n",
    "final_df = pd.merge(final_df, output_characters_genders_context[['IMDB_ID', 'character_name', 'gender']], on=['IMDB_ID', 'character_name'], how='left')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[59], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Export as csv\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mmerged_df_final\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mDATA/final.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/core/generic.py:3772\u001B[0m, in \u001B[0;36mNDFrame.to_csv\u001B[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001B[0m\n\u001B[1;32m   3761\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m, ABCDataFrame) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mto_frame()\n\u001B[1;32m   3763\u001B[0m formatter \u001B[38;5;241m=\u001B[39m DataFrameFormatter(\n\u001B[1;32m   3764\u001B[0m     frame\u001B[38;5;241m=\u001B[39mdf,\n\u001B[1;32m   3765\u001B[0m     header\u001B[38;5;241m=\u001B[39mheader,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3769\u001B[0m     decimal\u001B[38;5;241m=\u001B[39mdecimal,\n\u001B[1;32m   3770\u001B[0m )\n\u001B[0;32m-> 3772\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataFrameRenderer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mformatter\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_csv\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3773\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath_or_buf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3774\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlineterminator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlineterminator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3775\u001B[0m \u001B[43m    \u001B[49m\u001B[43msep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3776\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3777\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3778\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3779\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquoting\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquoting\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3780\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3781\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3782\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3783\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunksize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3784\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquotechar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquotechar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3785\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdate_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3786\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdoublequote\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdoublequote\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3787\u001B[0m \u001B[43m    \u001B[49m\u001B[43mescapechar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mescapechar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3788\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3789\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/io/formats/format.py:1186\u001B[0m, in \u001B[0;36mDataFrameRenderer.to_csv\u001B[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001B[0m\n\u001B[1;32m   1165\u001B[0m     created_buffer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1167\u001B[0m csv_formatter \u001B[38;5;241m=\u001B[39m CSVFormatter(\n\u001B[1;32m   1168\u001B[0m     path_or_buf\u001B[38;5;241m=\u001B[39mpath_or_buf,\n\u001B[1;32m   1169\u001B[0m     lineterminator\u001B[38;5;241m=\u001B[39mlineterminator,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1184\u001B[0m     formatter\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfmt,\n\u001B[1;32m   1185\u001B[0m )\n\u001B[0;32m-> 1186\u001B[0m \u001B[43mcsv_formatter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m created_buffer:\n\u001B[1;32m   1189\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(path_or_buf, StringIO)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/io/formats/csvs.py:259\u001B[0m, in \u001B[0;36mCSVFormatter.save\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_handle(\n\u001B[1;32m    241\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfilepath_or_buffer,\n\u001B[1;32m    242\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    247\u001B[0m ) \u001B[38;5;28;01mas\u001B[39;00m handles:\n\u001B[1;32m    248\u001B[0m     \u001B[38;5;66;03m# Note: self.encoding is irrelevant here\u001B[39;00m\n\u001B[1;32m    249\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwriter \u001B[38;5;241m=\u001B[39m csvlib\u001B[38;5;241m.\u001B[39mwriter(\n\u001B[1;32m    250\u001B[0m         handles\u001B[38;5;241m.\u001B[39mhandle,\n\u001B[1;32m    251\u001B[0m         lineterminator\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlineterminator,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    256\u001B[0m         quotechar\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mquotechar,\n\u001B[1;32m    257\u001B[0m     )\n\u001B[0;32m--> 259\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_save\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/io/formats/csvs.py:264\u001B[0m, in \u001B[0;36mCSVFormatter._save\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    262\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_need_to_save_header:\n\u001B[1;32m    263\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_save_header()\n\u001B[0;32m--> 264\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_save_body\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/io/formats/csvs.py:302\u001B[0m, in \u001B[0;36mCSVFormatter._save_body\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    300\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m start_i \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m end_i:\n\u001B[1;32m    301\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m--> 302\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_save_chunk\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstart_i\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mend_i\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/io/formats/csvs.py:313\u001B[0m, in \u001B[0;36mCSVFormatter._save_chunk\u001B[0;34m(self, start_i, end_i)\u001B[0m\n\u001B[1;32m    310\u001B[0m data \u001B[38;5;241m=\u001B[39m [res\u001B[38;5;241m.\u001B[39miget_values(i) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(res\u001B[38;5;241m.\u001B[39mitems))]\n\u001B[1;32m    312\u001B[0m ix \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_index[slicer]\u001B[38;5;241m.\u001B[39m_format_native_types(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_number_format)\n\u001B[0;32m--> 313\u001B[0m \u001B[43mlibwriters\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite_csv_rows\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    314\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    315\u001B[0m \u001B[43m    \u001B[49m\u001B[43mix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    316\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnlevels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    317\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcols\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    318\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwriter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    319\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/_libs/writers.pyx:72\u001B[0m, in \u001B[0;36mpandas._libs.writers.write_csv_rows\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ada/lib/python3.9/site-packages/nltk/tree/tree.py:787\u001B[0m, in \u001B[0;36mTree.__str__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    786\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__str__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 787\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpformat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ada/lib/python3.9/site-packages/nltk/tree/tree.py:817\u001B[0m, in \u001B[0;36mTree.pformat\u001B[0;34m(self, margin, indent, nodesep, parens, quotes)\u001B[0m\n\u001B[1;32m    802\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    803\u001B[0m \u001B[38;5;124;03m:return: A pretty-printed string representation of this tree.\u001B[39;00m\n\u001B[1;32m    804\u001B[0m \u001B[38;5;124;03m:rtype: str\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    813\u001B[0m \u001B[38;5;124;03m    trees like ``(S: (NP: I) (VP: (V: saw) (NP: it)))``.\u001B[39;00m\n\u001B[1;32m    814\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    816\u001B[0m \u001B[38;5;66;03m# Try writing it on one line.\u001B[39;00m\n\u001B[0;32m--> 817\u001B[0m s \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_pformat_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnodesep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparens\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquotes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    818\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(s) \u001B[38;5;241m+\u001B[39m indent \u001B[38;5;241m<\u001B[39m margin:\n\u001B[1;32m    819\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m s\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ada/lib/python3.9/site-packages/nltk/tree/tree.py:880\u001B[0m, in \u001B[0;36mTree._pformat_flat\u001B[0;34m(self, nodesep, parens, quotes)\u001B[0m\n\u001B[1;32m    874\u001B[0m         childstrs\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mrepr\u001B[39m(child))\n\u001B[1;32m    875\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_label, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    876\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    877\u001B[0m         parens[\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m    878\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_label,\n\u001B[1;32m    879\u001B[0m         nodesep,\n\u001B[0;32m--> 880\u001B[0m         \u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchildstrs\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m    881\u001B[0m         parens[\u001B[38;5;241m1\u001B[39m],\n\u001B[1;32m    882\u001B[0m     )\n\u001B[1;32m    883\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    884\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    885\u001B[0m         parens[\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m    886\u001B[0m         \u001B[38;5;28mrepr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_label),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    889\u001B[0m         parens[\u001B[38;5;241m1\u001B[39m],\n\u001B[1;32m    890\u001B[0m     )\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "characters_data=pd.read_csv('DATA/characters_data.csv',low_memory=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "to_save_df = pd.merge(characters_data, final_df, on=['IMDB_ID', 'character_name'], how='left')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "to_save_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "to_save_df.to_csv('DATA/characters_personas_data.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "male_dict, female_dict = create_gender_dictionaries(result_df_with_context)\n",
    "print(\"Male Dictionary:\")\n",
    "print(male_dict)\n",
    "print(\"\\nFemale Dictionary:\")\n",
    "print(female_dict)\n",
    "\n",
    "# Calculate word frequencies for male and female characters\n",
    "male_frequencies = calculate_word_frequencies(male_dict)\n",
    "female_frequencies = calculate_word_frequencies(female_dict)\n",
    "\n",
    "# Print or use the frequencies as needed\n",
    "print(\"Male Word Frequencies:\")\n",
    "print(male_frequencies)\n",
    "print(\"\\nFemale Word Frequencies:\")\n",
    "print(female_frequencies)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_top_words(frequencies, category, gender, top_n=5):\n",
    "    words = list(frequencies[category].keys())\n",
    "    values = list(frequencies[category].values())\n",
    "\n",
    "    # Get the top N words and their frequencies\n",
    "    top_words = [word for _, word in sorted(zip(values, words), reverse=True)[:top_n]]\n",
    "    top_frequencies = [frequencies[category][word] for word in top_words]\n",
    "\n",
    "    # Plot the bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(top_words, top_frequencies, color='skyblue')\n",
    "    plt.title(f'Top 5 {category} Words for {gender} Characters')\n",
    "    plt.xlabel('Words')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have already obtained the male and female frequencies\n",
    "# male_frequencies, female_frequencies = calculate_word_frequencies(male_dict), calculate_word_frequencies(female_dict)\n",
    "\n",
    "# Plot the top 5 words for each category for male characters\n",
    "for category in ['Verbs', 'Adjectives', 'Nouns']:\n",
    "    plot_top_words(male_frequencies, category, 'Male')\n",
    "\n",
    "# Plot the top 5 words for each category for female characters\n",
    "for category in ['Verbs', 'Adjectives', 'Nouns']:\n",
    "    plot_top_words(female_frequencies, category, 'Female')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
