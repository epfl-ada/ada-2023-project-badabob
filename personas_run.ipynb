{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d1fe2a5-416d-47b6-afa4-aa5a98ba9249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm # Progress bar\n",
    "\n",
    "from fuzzywuzzy import process\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fcd260b-25e6-4af2-ad9e-6db0b7656ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_characters_genders_context=pd.read_csv('DATA/output_characters_genders_context.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "575cb115",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "verb_tags=['VB','VBD','VBG','VBN','VBP','VBZ']\n",
    "adj_tags=['JJ','JJR','JJS']\n",
    "noun_tags=['NN','NNS','NNP','NNPS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f1bb9fa",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with empty 'associated words' column: 10513\n"
     ]
    }
   ],
   "source": [
    "# Count number of rows with missing associated_words\n",
    "empty_rows = output_characters_genders_context[output_characters_genders_context['associated_words'].isnull() | (output_characters_genders_context['associated_words'] == '')]\n",
    "count_empty_rows = empty_rows.shape[0]\n",
    "print(f\"Number of rows with empty 'associated words' column: {count_empty_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc8f1f4-b6b5-4007-ad6a-321f38e28d62",
   "metadata": {},
   "source": [
    "Modif initial fct to keep the id column for later merges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3497bda-f543-47cc-b71f-18117a0d20fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_words(df, id_col, char_name_col, to_extract):\n",
    "    tokens = pd.Series()\n",
    "    tagged_tokens = []\n",
    "    chunks_array = []\n",
    "    verbs_list = []\n",
    "    adjs_list = []\n",
    "    nouns_list = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Create tqdm progress bar for the loop\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing Movies\"):\n",
    "        verbs = []\n",
    "        adjs = []\n",
    "        nouns = []\n",
    "        text = row[to_extract]\n",
    "        associated_w_text = row[char_name_col]\n",
    "        movie_id = row[id_col]\n",
    "        \n",
    "        if type(text) == str:  # To only keep movies with a summary (ignoring NaN)\n",
    "            token = [word for word in nltk.word_tokenize(text) if word.lower() not in stop_words]  # Removing stopwords\n",
    "            tokens[associated_w_text] = token\n",
    "            tagged_tokens.append((movie_id, associated_w_text, nltk.pos_tag(token)))\n",
    "\n",
    "    # Tqdm progress bar for the second loop\n",
    "    for movie_id, associated_w_text, tagged_token in tqdm(tagged_tokens, desc=\"Processing Tokens\", leave=False):\n",
    "        chunks_array.append((movie_id, associated_w_text, nltk.ne_chunk(tagged_token)))\n",
    "\n",
    "        verbs = []\n",
    "        adjs = []\n",
    "        nouns = []\n",
    "\n",
    "        # Categorize\n",
    "        for word, pos_tag in tagged_token:\n",
    "            if pos_tag in verb_tags:\n",
    "                verbs.append(word)\n",
    "            elif pos_tag in adj_tags:\n",
    "                adjs.append(word)\n",
    "            elif pos_tag in noun_tags:\n",
    "                nouns.append(word)\n",
    "\n",
    "        verbs_list.append((movie_id, associated_w_text, verbs))\n",
    "        adjs_list.append((movie_id, associated_w_text, adjs))\n",
    "        nouns_list.append((movie_id, associated_w_text, nouns))\n",
    "\n",
    "    # Returns lists of all verbs, adjectives, and nouns for each movie and raw chunks for each movie\n",
    "    return verbs_list, adjs_list, nouns_list, chunks_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f4bd861-6ba2-4817-9be3-6eb0e0041778",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Movies: 100%|██████████| 176334/176334 [18:12<00:00, 161.36it/s] \n",
      "                                                                            \r"
     ]
    }
   ],
   "source": [
    "verbs, adjs, nouns, chunks = extract_words(output_characters_genders_context, \"IMDB_ID\", \"character_name\",\"associated_words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b207a5ba-6a7e-4313-9c3f-cd0e4a2ceceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames from the lists\n",
    "verbs_df = pd.DataFrame(verbs, columns=['IMDB_ID', 'character_name', 'Verbs'])\n",
    "adjs_df = pd.DataFrame(adjs, columns=['IMDB_ID', 'character_name', 'Adjectives'])\n",
    "nouns_df = pd.DataFrame(nouns, columns=['IMDB_ID', 'character_name', 'Nouns'])\n",
    "chunks_df = pd.DataFrame(chunks, columns=['IMDB_ID', 'character_name', 'Chunks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e50af8cb-758d-40b7-b58d-76430218efb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge DataFrames on 'IMDB_ID' and 'character_name'\n",
    "final_df = verbs_df.merge(adjs_df, on=['IMDB_ID', 'character_name']) \\\n",
    "                    .merge(nouns_df, on=['IMDB_ID', 'character_name']) \\\n",
    "                    .merge(chunks_df, on=['IMDB_ID', 'character_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3844eb29-89af-489b-aa8e-1d2580138195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to have the genders, use that df if it is too big to merge with the character_data and save to csv\n",
    "# DO NOT RUN THAT CELL IF RUN THE NEXT ONE BECAUSE THE GENDER COLUMN WILL BE DUPLICATED\n",
    "final_df = pd.merge(final_df, output_characters_genders_context[['IMDB_ID', 'character_name', 'gender']], on=['IMDB_ID', 'character_name'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9b1ca1e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMDB_ID</th>\n",
       "      <th>character_name</th>\n",
       "      <th>Verbs</th>\n",
       "      <th>Adjectives</th>\n",
       "      <th>Nouns</th>\n",
       "      <th>Chunks</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0228333</td>\n",
       "      <td>Sgt Jericho Butler</td>\n",
       "      <td>[walk, wearing, sent, opened, released, posses...</td>\n",
       "      <td>[second, pick, disembodied, possible, Unfortun...</td>\n",
       "      <td>[half, humans, surface, pressure, suits, team,...</td>\n",
       "      <td>[(second, JJ), (half, NN), (22nd, CD), (humans...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0228333</td>\n",
       "      <td>Bashira Kincaid</td>\n",
       "      <td>[killed, returning, blame, cot, escapes, leaving]</td>\n",
       "      <td>[massacre]</td>\n",
       "      <td>[pick, transport, prisoner, Desolation, Willia...</td>\n",
       "      <td>[(pick, NN), (transport, NN), (prisoner, NN), ...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0228333</td>\n",
       "      <td>Michael Descanso</td>\n",
       "      <td>[planet, finds, missing, discovered, discovere...</td>\n",
       "      <td>[second, 22nd, 22nd, doorway, ancient, Martian...</td>\n",
       "      <td>[Set, century, film, century, film, Mars, mini...</td>\n",
       "      <td>[[(Set, NNP)], (second, JJ), (22nd, JJ), (cent...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0228333</td>\n",
       "      <td>Big Daddy Mars</td>\n",
       "      <td>[planet, terraformed]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[century, film, depicts]</td>\n",
       "      <td>[(century, NN), (film, NN), (depicts, NNS), (p...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0228333</td>\n",
       "      <td>Akooshay</td>\n",
       "      <td>[discovered, created, wiped]</td>\n",
       "      <td>[second, 22nd, ancient, fierce]</td>\n",
       "      <td>[Set, century, film, miners, Martian, miners, ...</td>\n",
       "      <td>[[(Set, NNP)], (second, JJ), (22nd, JJ), (cent...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165816</th>\n",
       "      <td>tt9913288</td>\n",
       "      <td>Trent Osborne</td>\n",
       "      <td>[come, mail, mail, mail, unmarked]</td>\n",
       "      <td>[piece, unmarked, red]</td>\n",
       "      <td>[day, home, bills, get, bills, mail, stands, s...</td>\n",
       "      <td>[(day, NN), (come, VB), (home, NN), (bills, NN...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165817</th>\n",
       "      <td>tt9914522</td>\n",
       "      <td>Mackenzie</td>\n",
       "      <td>[murdered, regarding, make, regarding]</td>\n",
       "      <td>[new, niece]</td>\n",
       "      <td>[Holden, sister, brother, law, husband, Evan, ...</td>\n",
       "      <td>[[(Holden, NNP)], (sister, NN), (brother, NN),...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165818</th>\n",
       "      <td>tt9914522</td>\n",
       "      <td>Evan's dad</td>\n",
       "      <td>[make, regarding, regarding]</td>\n",
       "      <td>[new]</td>\n",
       "      <td>[Mackenzie, husband, decision, make, niece]</td>\n",
       "      <td>[[(Mackenzie, NNP)], (new, JJ), (husband, NN),...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165819</th>\n",
       "      <td>tt9914522</td>\n",
       "      <td>Jade</td>\n",
       "      <td>[make]</td>\n",
       "      <td>[new]</td>\n",
       "      <td>[honeymoon, Mackenzie, Evan, decision, make, r...</td>\n",
       "      <td>[(honeymoon, NN), [(Mackenzie, NNP)], (new, JJ...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165820</th>\n",
       "      <td>tt9914522</td>\n",
       "      <td>Evan</td>\n",
       "      <td>[make, regarding]</td>\n",
       "      <td>[new]</td>\n",
       "      <td>[Mackenzie, husband, decision]</td>\n",
       "      <td>[[(Mackenzie, NNP)], (new, JJ), (husband, NN),...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165821 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          IMDB_ID      character_name  \\\n",
       "0       tt0228333  Sgt Jericho Butler   \n",
       "1       tt0228333     Bashira Kincaid   \n",
       "2       tt0228333    Michael Descanso   \n",
       "3       tt0228333      Big Daddy Mars   \n",
       "4       tt0228333            Akooshay   \n",
       "...           ...                 ...   \n",
       "165816  tt9913288       Trent Osborne   \n",
       "165817  tt9914522           Mackenzie   \n",
       "165818  tt9914522          Evan's dad   \n",
       "165819  tt9914522                Jade   \n",
       "165820  tt9914522                Evan   \n",
       "\n",
       "                                                    Verbs  \\\n",
       "0       [walk, wearing, sent, opened, released, posses...   \n",
       "1       [killed, returning, blame, cot, escapes, leaving]   \n",
       "2       [planet, finds, missing, discovered, discovere...   \n",
       "3                                   [planet, terraformed]   \n",
       "4                            [discovered, created, wiped]   \n",
       "...                                                   ...   \n",
       "165816                 [come, mail, mail, mail, unmarked]   \n",
       "165817             [murdered, regarding, make, regarding]   \n",
       "165818                       [make, regarding, regarding]   \n",
       "165819                                             [make]   \n",
       "165820                                  [make, regarding]   \n",
       "\n",
       "                                               Adjectives  \\\n",
       "0       [second, pick, disembodied, possible, Unfortun...   \n",
       "1                                              [massacre]   \n",
       "2       [second, 22nd, 22nd, doorway, ancient, Martian...   \n",
       "3                                                      []   \n",
       "4                         [second, 22nd, ancient, fierce]   \n",
       "...                                                   ...   \n",
       "165816                             [piece, unmarked, red]   \n",
       "165817                                       [new, niece]   \n",
       "165818                                              [new]   \n",
       "165819                                              [new]   \n",
       "165820                                              [new]   \n",
       "\n",
       "                                                    Nouns  \\\n",
       "0       [half, humans, surface, pressure, suits, team,...   \n",
       "1       [pick, transport, prisoner, Desolation, Willia...   \n",
       "2       [Set, century, film, century, film, Mars, mini...   \n",
       "3                                [century, film, depicts]   \n",
       "4       [Set, century, film, miners, Martian, miners, ...   \n",
       "...                                                   ...   \n",
       "165816  [day, home, bills, get, bills, mail, stands, s...   \n",
       "165817  [Holden, sister, brother, law, husband, Evan, ...   \n",
       "165818        [Mackenzie, husband, decision, make, niece]   \n",
       "165819  [honeymoon, Mackenzie, Evan, decision, make, r...   \n",
       "165820                     [Mackenzie, husband, decision]   \n",
       "\n",
       "                                                   Chunks gender  \n",
       "0       [(second, JJ), (half, NN), (22nd, CD), (humans...      M  \n",
       "1       [(pick, NN), (transport, NN), (prisoner, NN), ...      F  \n",
       "2       [[(Set, NNP)], (second, JJ), (22nd, JJ), (cent...      M  \n",
       "3       [(century, NN), (film, NN), (depicts, NNS), (p...      M  \n",
       "4       [[(Set, NNP)], (second, JJ), (22nd, JJ), (cent...      F  \n",
       "...                                                   ...    ...  \n",
       "165816  [(day, NN), (come, VB), (home, NN), (bills, NN...      M  \n",
       "165817  [[(Holden, NNP)], (sister, NN), (brother, NN),...      F  \n",
       "165818  [[(Mackenzie, NNP)], (new, JJ), (husband, NN),...      M  \n",
       "165819  [(honeymoon, NN), [(Mackenzie, NNP)], (new, JJ...      F  \n",
       "165820  [[(Mackenzie, NNP)], (new, JJ), (husband, NN),...      M  \n",
       "\n",
       "[165821 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d751c18f-d88d-4723-b382-f30e3ea0bde4",
   "metadata": {},
   "source": [
    "previous cell gives df with columns IMDB_ID\tcharacter_name\tVerbs\tAdjectives\tNouns\tChunks\tgender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40876bb9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "characters_data=pd.read_csv('DATA/characters_data.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcd2c931-00b9-4f45-9384-33de2a4afb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save_df = pd.merge(characters_data, final_df, on=['IMDB_ID', 'character_name'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fcb8811",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_ID</th>\n",
       "      <th>wikipedia_ID</th>\n",
       "      <th>freebase_ID</th>\n",
       "      <th>actor_ethnicity</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>personnas</th>\n",
       "      <th>IMDB_ID</th>\n",
       "      <th>character_name</th>\n",
       "      <th>actor_gender</th>\n",
       "      <th>box_office_revenue</th>\n",
       "      <th>name</th>\n",
       "      <th>release_date</th>\n",
       "      <th>actor_age</th>\n",
       "      <th>Verbs</th>\n",
       "      <th>Adjectives</th>\n",
       "      <th>Nouns</th>\n",
       "      <th>Chunks</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>975900.0</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wanda de jesus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0228333</td>\n",
       "      <td>Akooshay</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>[discovered, created, wiped]</td>\n",
       "      <td>[second, 22nd, ancient, fierce]</td>\n",
       "      <td>[Set, century, film, miners, Martian, miners, ...</td>\n",
       "      <td>[[(Set, NNP)], (second, JJ), (22nd, JJ), (cent...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>975900.0</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>/m/044038p</td>\n",
       "      <td>natasha henstridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0228333</td>\n",
       "      <td>Lieutenant Melanie Ballard</td>\n",
       "      <td>F</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>[terraformed, allowing, become, authority, sen...</td>\n",
       "      <td>[matriarchal, police, second, second, small, s...</td>\n",
       "      <td>[film, depicts, Mars, positions, story, concer...</td>\n",
       "      <td>[(film, NN), (depicts, NNS), (Mars, NNP), (84,...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>975900.0</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>/m/0x67</td>\n",
       "      <td>ice cube</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0228333</td>\n",
       "      <td>Desolation Williams</td>\n",
       "      <td>M</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>[wearing, become, named, named, held, mining, ...</td>\n",
       "      <td>[transport, remote, ancient, horrific, team, d...</td>\n",
       "      <td>[pressure, suits, society, prisoner, Williams,...</td>\n",
       "      <td>[(wearing, VBG), (pressure, NN), (suits, NNS),...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>975900.0</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jason statham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0228333</td>\n",
       "      <td>Sgt Jericho Butler</td>\n",
       "      <td>M</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>[walk, wearing, sent, opened, released, posses...</td>\n",
       "      <td>[second, pick, disembodied, possible, Unfortun...</td>\n",
       "      <td>[half, humans, surface, pressure, suits, team,...</td>\n",
       "      <td>[(second, JJ), (half, NN), (22nd, CD), (humans...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>975900.0</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clea duvall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0228333</td>\n",
       "      <td>Bashira Kincaid</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>[killed, returning, blame, cot, escapes, leaving]</td>\n",
       "      <td>[massacre]</td>\n",
       "      <td>[pick, transport, prisoner, Desolation, Willia...</td>\n",
       "      <td>[(pick, NN), (transport, NN), (prisoner, NN), ...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336453</th>\n",
       "      <td>336454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>caleb silvers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt9914522</td>\n",
       "      <td>Evan</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Holden Family Plan</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>[make, regarding]</td>\n",
       "      <td>[new]</td>\n",
       "      <td>[Mackenzie, husband, decision]</td>\n",
       "      <td>[[(Mackenzie, NNP)], (new, JJ), (husband, NN),...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336454</th>\n",
       "      <td>336455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bethany hazelitt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt9914522</td>\n",
       "      <td>Mackenzie</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Holden Family Plan</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>[murdered, regarding, make, regarding]</td>\n",
       "      <td>[new, niece]</td>\n",
       "      <td>[Holden, sister, brother, law, husband, Evan, ...</td>\n",
       "      <td>[[(Holden, NNP)], (sister, NN), (brother, NN),...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336455</th>\n",
       "      <td>336456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>joshua bootz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt9914522</td>\n",
       "      <td>Evan's dad</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Holden Family Plan</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[make, regarding, regarding]</td>\n",
       "      <td>[new]</td>\n",
       "      <td>[Mackenzie, husband, decision, make, niece]</td>\n",
       "      <td>[[(Mackenzie, NNP)], (new, JJ), (husband, NN),...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336456</th>\n",
       "      <td>336457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vince camaj</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt9914522</td>\n",
       "      <td>Todd</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Holden Family Plan</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336457</th>\n",
       "      <td>336458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sandra gendjar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt9914522</td>\n",
       "      <td>Kelsey</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Holden Family Plan</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336458 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        character_ID  wikipedia_ID freebase_ID actor_ethnicity  \\\n",
       "0                  1      975900.0   /m/03vyhn             NaN   \n",
       "1                  2      975900.0   /m/03vyhn      /m/044038p   \n",
       "2                  3      975900.0   /m/03vyhn         /m/0x67   \n",
       "3                  4      975900.0   /m/03vyhn             NaN   \n",
       "4                  5      975900.0   /m/03vyhn             NaN   \n",
       "...              ...           ...         ...             ...   \n",
       "336453        336454           NaN         NaN             NaN   \n",
       "336454        336455           NaN         NaN             NaN   \n",
       "336455        336456           NaN         NaN             NaN   \n",
       "336456        336457           NaN         NaN             NaN   \n",
       "336457        336458           NaN         NaN             NaN   \n",
       "\n",
       "                actor_name personnas    IMDB_ID              character_name  \\\n",
       "0           wanda de jesus       NaN  tt0228333                    Akooshay   \n",
       "1       natasha henstridge       NaN  tt0228333  Lieutenant Melanie Ballard   \n",
       "2                 ice cube       NaN  tt0228333         Desolation Williams   \n",
       "3            jason statham       NaN  tt0228333          Sgt Jericho Butler   \n",
       "4              clea duvall       NaN  tt0228333             Bashira Kincaid   \n",
       "...                    ...       ...        ...                         ...   \n",
       "336453       caleb silvers       NaN  tt9914522                        Evan   \n",
       "336454    bethany hazelitt       NaN  tt9914522                   Mackenzie   \n",
       "336455        joshua bootz       NaN  tt9914522                  Evan's dad   \n",
       "336456         vince camaj       NaN  tt9914522                        Todd   \n",
       "336457      sandra gendjar       NaN  tt9914522                      Kelsey   \n",
       "\n",
       "       actor_gender  box_office_revenue                    name  release_date  \\\n",
       "0                 F                 NaN          Ghosts of Mars        2001.0   \n",
       "1                 F          14010832.0          Ghosts of Mars        2001.0   \n",
       "2                 M          14010832.0          Ghosts of Mars        2001.0   \n",
       "3                 M          14010832.0          Ghosts of Mars        2001.0   \n",
       "4                 F                 NaN          Ghosts of Mars        2001.0   \n",
       "...             ...                 ...                     ...           ...   \n",
       "336453            M                 NaN  The Holden Family Plan        2019.0   \n",
       "336454            F                 NaN  The Holden Family Plan        2019.0   \n",
       "336455            M                 NaN  The Holden Family Plan        2019.0   \n",
       "336456            M                 NaN  The Holden Family Plan        2019.0   \n",
       "336457            F                 NaN  The Holden Family Plan        2019.0   \n",
       "\n",
       "        actor_age                                              Verbs  \\\n",
       "0            42.0                       [discovered, created, wiped]   \n",
       "1            27.0  [terraformed, allowing, become, authority, sen...   \n",
       "2            32.0  [wearing, become, named, named, held, mining, ...   \n",
       "3            34.0  [walk, wearing, sent, opened, released, posses...   \n",
       "4            23.0  [killed, returning, blame, cot, escapes, leaving]   \n",
       "...           ...                                                ...   \n",
       "336453       24.0                                  [make, regarding]   \n",
       "336454       29.0             [murdered, regarding, make, regarding]   \n",
       "336455        NaN                       [make, regarding, regarding]   \n",
       "336456        NaN                                                NaN   \n",
       "336457        NaN                                                NaN   \n",
       "\n",
       "                                               Adjectives  \\\n",
       "0                         [second, 22nd, ancient, fierce]   \n",
       "1       [matriarchal, police, second, second, small, s...   \n",
       "2       [transport, remote, ancient, horrific, team, d...   \n",
       "3       [second, pick, disembodied, possible, Unfortun...   \n",
       "4                                              [massacre]   \n",
       "...                                                   ...   \n",
       "336453                                              [new]   \n",
       "336454                                       [new, niece]   \n",
       "336455                                              [new]   \n",
       "336456                                                NaN   \n",
       "336457                                                NaN   \n",
       "\n",
       "                                                    Nouns  \\\n",
       "0       [Set, century, film, miners, Martian, miners, ...   \n",
       "1       [film, depicts, Mars, positions, story, concer...   \n",
       "2       [pressure, suits, society, prisoner, Williams,...   \n",
       "3       [half, humans, surface, pressure, suits, team,...   \n",
       "4       [pick, transport, prisoner, Desolation, Willia...   \n",
       "...                                                   ...   \n",
       "336453                     [Mackenzie, husband, decision]   \n",
       "336454  [Holden, sister, brother, law, husband, Evan, ...   \n",
       "336455        [Mackenzie, husband, decision, make, niece]   \n",
       "336456                                                NaN   \n",
       "336457                                                NaN   \n",
       "\n",
       "                                                   Chunks gender  \n",
       "0       [[(Set, NNP)], (second, JJ), (22nd, JJ), (cent...      F  \n",
       "1       [(film, NN), (depicts, NNS), (Mars, NNP), (84,...      F  \n",
       "2       [(wearing, VBG), (pressure, NN), (suits, NNS),...      M  \n",
       "3       [(second, JJ), (half, NN), (22nd, CD), (humans...      M  \n",
       "4       [(pick, NN), (transport, NN), (prisoner, NN), ...      F  \n",
       "...                                                   ...    ...  \n",
       "336453  [[(Mackenzie, NNP)], (new, JJ), (husband, NN),...      M  \n",
       "336454  [[(Holden, NNP)], (sister, NN), (brother, NN),...      F  \n",
       "336455  [[(Mackenzie, NNP)], (new, JJ), (husband, NN),...      M  \n",
       "336456                                                NaN    NaN  \n",
       "336457                                                NaN    NaN  \n",
       "\n",
       "[336458 rows x 18 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_save_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d23170a1-b722-4d69-bbd2-13e6ec621c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save_df.to_csv('DATA/characters_personas_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10e33ac-2601-479b-87ef-7a9b553ff075",
   "metadata": {},
   "source": [
    "### CA DEVRAIT MARCHER !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ebc8ab",
   "metadata": {},
   "source": [
    "### Checking sizes before and after extract_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33aa1605",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: 176334 after: 165821 before-after: 10513 number of empty rows: 10513\n"
     ]
    }
   ],
   "source": [
    "before=len(output_characters_genders_context)\n",
    "after=len(final_df)\n",
    "print('before:',before,'after:',after,'before-after:',before-after,'number of empty rows:',count_empty_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c604dcb",
   "metadata": {},
   "source": [
    "This explains the difference in sizes before and after extract_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395e757b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
